{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epistasis plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/ProteinGym_subs_apr_2024'\n",
    "suitable_datasets = []\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'mutant' in df.columns:\n",
    "            mutations = df['mutant']\n",
    "            for mut in mutations:\n",
    "                if len(mut.split(':')) > 1:\n",
    "                    suitable_datasets.append(file_path)\n",
    "                    break\n",
    "        else:\n",
    "            print(filename, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = '../selected_datasets.txt'\n",
    "\n",
    "# Open the file in write mode and write the strings line by line\n",
    "with open(file_path, 'w') as file:\n",
    "    for string in suitable_datasets:\n",
    "        file.write(string.split('/')[-1].split('.')[0] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in suitable_datasets:\n",
    "    name = dataset.split('/')[-1].split('.')[0]\n",
    "    df = pd.read_csv(dataset)\n",
    "    indices = {}\n",
    "    for ind, row in df.iterrows():\n",
    "        mutations = row['mutant'].split(':')\n",
    "        if len(mutations) == 2:\n",
    "            indices[(mutations[0], mutations[1], ind)] = [-1, -1]\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        mutations = row['mutant'].split(':')\n",
    "        if len(mutations) == 1:\n",
    "            for key, value in indices.items():\n",
    "                if key[0] == mutations[0]:\n",
    "                    indices[key][0] = ind\n",
    "                if key[1] == mutations[0]:\n",
    "                    indices[key][1] = ind\n",
    "\n",
    "    dic_final = {}\n",
    "    for key, value in indices.items():\n",
    "        if value[0] != -1 and value[1] != -1:\n",
    "            dic_final[key] = value\n",
    "\n",
    "    #df['DMS_score_log'] = np.log1p(df['DMS_score'])\n",
    "    scaler = MinMaxScaler()\n",
    "    df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    selected = []\n",
    "    for key, value in dic_final.items():\n",
    "        ind = key[2]\n",
    "        x.append(df.loc[ind, 'DMS_score_scaled'])\n",
    "        selected.append(key[0] + ':' + key[1])\n",
    "        ind_first = value[0]\n",
    "        ind_second = value[1]\n",
    "        y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled'])\n",
    "\n",
    "    # Calculate distances from the line y = x\n",
    "    distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "    # Calculate mean and standard deviation of the distances\n",
    "    mean_distance = np.mean(distances)\n",
    "    std_distance = np.std(distances)\n",
    "    # Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "    threshold = mean_distance + 2 * std_distance\n",
    "    # Identify points that are \"distinct\"\n",
    "    distinct_points = distances > threshold\n",
    "    distinct_x = np.array(x)[distinct_points.tolist()]\n",
    "    distinct_y = np.array(y)[distinct_points.tolist()]\n",
    "    selected_mutations = [element for element, mask in zip(selected, distinct_points.tolist()) if mask]\n",
    "\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    plt.figure(figsize=[8,8])\n",
    "    plt.scatter(x, y, color=cmap(1), alpha=0.8, label='near points')\n",
    "    plt.scatter(distinct_x, distinct_y, color=cmap(0), alpha=0.8, label='distinct points')\n",
    "    plt.plot([0, 1], [0, 1], color='grey', alpha=0.8, linestyle='--', label='y=x')\n",
    "    plt.xlabel('Double mutation', fontsize=14)\n",
    "    plt.ylabel('Multiplication of single mutations', fontsize=14)\n",
    "    plt.title(f'Measured fluorescence values {name}', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'../figures/plots_datasets/2std/{name}.svg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "subsets = []\n",
    "start = 0\n",
    "while start != 60:\n",
    "    subsets.append(suitable_datasets[start:start+12])\n",
    "    start += 12\n",
    "subsets.append(suitable_datasets[start:])\n",
    "for num in range(len(subsets)):\n",
    "    subset = subsets[num]\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20, 30))\n",
    "    for index in range(len(subset)):\n",
    "        dataset = subset[index]\n",
    "        name = dataset.split('/')[-1].split('.')[0]\n",
    "        df = pd.read_csv(dataset)\n",
    "        indices = {}\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 2:\n",
    "                indices[(mutations[0], mutations[1], ind)] = [-1, -1]\n",
    "\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 1:\n",
    "                for key, value in indices.items():\n",
    "                    if key[0] == mutations[0]:\n",
    "                        indices[key][0] = ind\n",
    "                    if key[1] == mutations[0]:\n",
    "                        indices[key][1] = ind\n",
    "\n",
    "        dic_final = {}\n",
    "        for key, value in indices.items():\n",
    "            if value[0] != -1 and value[1] != -1:\n",
    "                dic_final[key] = value\n",
    "\n",
    "        #df['DMS_score_log'] = np.log1p(df['DMS_score'])\n",
    "        scaler = MinMaxScaler()\n",
    "        df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1))\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        selected = []\n",
    "        for key, value in dic_final.items():\n",
    "            ind = key[2]\n",
    "            x.append(df.loc[ind, 'DMS_score_scaled'])\n",
    "            selected.append(key[0] + ':' + key[1])\n",
    "            ind_first = value[0]\n",
    "            ind_second = value[1]\n",
    "            y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled'])\n",
    "\n",
    "        # Calculate distances from the line y = x\n",
    "        distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "        # Calculate mean and standard deviation of the distances\n",
    "        mean_distance = np.mean(distances)\n",
    "        std_distance = np.std(distances)\n",
    "        # Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "        threshold = mean_distance + 1 * std_distance\n",
    "        # Identify points that are \"distinct\"\n",
    "        distinct_points = distances > threshold\n",
    "        distinct_x = np.array(x)[distinct_points.tolist()]\n",
    "        distinct_y = np.array(y)[distinct_points.tolist()]\n",
    "        selected_mutations = [element for element, mask in zip(selected, distinct_points.tolist()) if mask]\n",
    "\n",
    "        i = index // 3\n",
    "        j = index % 3\n",
    "        cmap = plt.get_cmap('Paired')\n",
    "        axes[i, j].scatter(x, y, color=cmap(1), alpha=0.8, label='near points')\n",
    "        axes[i, j].scatter(distinct_x, distinct_y, color=cmap(0), alpha=0.8, label='distinct points')\n",
    "        axes[i, j].plot([0, 1], [0, 1], color='grey', alpha=0.8, linestyle='--', label='y=x')\n",
    "        axes[i, j].set_title(f'{name}')\n",
    "        axes[i, j].set_xlabel('Double mutation')\n",
    "        axes[i, j].set_ylabel('Multiplication of single mutations')\n",
    "        axes[i, j].legend()\n",
    "        axes[i, j].grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/plots_datasets/1std/all_1std_part{num}.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "subsets = []\n",
    "start = 0\n",
    "while start != 60:\n",
    "    subsets.append(suitable_datasets[start:start+12])\n",
    "    start += 12\n",
    "subsets.append(suitable_datasets[start:])\n",
    "for num in range(len(subsets)):\n",
    "    subset = subsets[num]\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20, 30))\n",
    "    for index in range(len(subset)):\n",
    "        dataset = subset[index]\n",
    "        name = dataset.split('/')[-1].split('.')[0]\n",
    "        df = pd.read_csv(dataset)\n",
    "        indices = {}\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 2:\n",
    "                indices[(mutations[0], mutations[1], ind)] = [-1, -1]\n",
    "\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 1:\n",
    "                for key, value in indices.items():\n",
    "                    if key[0] == mutations[0]:\n",
    "                        indices[key][0] = ind\n",
    "                    if key[1] == mutations[0]:\n",
    "                        indices[key][1] = ind\n",
    "\n",
    "        dic_final = {}\n",
    "        for key, value in indices.items():\n",
    "            if value[0] != -1 and value[1] != -1:\n",
    "                dic_final[key] = value\n",
    "\n",
    "        #df['DMS_score_log'] = np.log1p(df['DMS_score'])\n",
    "        scaler = MinMaxScaler()\n",
    "        df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1))\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        selected = []\n",
    "        for key, value in dic_final.items():\n",
    "            ind = key[2]\n",
    "            x.append(df.loc[ind, 'DMS_score_scaled'])\n",
    "            selected.append(key[0] + ':' + key[1])\n",
    "            ind_first = value[0]\n",
    "            ind_second = value[1]\n",
    "            y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled'])\n",
    "\n",
    "        # Calculate distances from the line y = x\n",
    "        distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "        # Calculate mean and standard deviation of the distances\n",
    "        mean_distance = np.mean(distances)\n",
    "        std_distance = np.std(distances)\n",
    "        # Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "        threshold = mean_distance + 2 * std_distance\n",
    "        # Identify points that are \"distinct\"\n",
    "        distinct_points = distances > threshold\n",
    "        distinct_x = np.array(x)[distinct_points.tolist()]\n",
    "        distinct_y = np.array(y)[distinct_points.tolist()]\n",
    "        selected_mutations = [element for element, mask in zip(selected, distinct_points.tolist()) if mask]\n",
    "\n",
    "        i = index // 3\n",
    "        j = index % 3\n",
    "        cmap = plt.get_cmap('Paired')\n",
    "        axes[i, j].scatter(x, y, color=cmap(1), alpha=0.8, label='near points')\n",
    "        axes[i, j].scatter(distinct_x, distinct_y, color=cmap(0), alpha=0.8, label='distinct points')\n",
    "        axes[i, j].plot([0, 1], [0, 1], color='grey', alpha=0.8, linestyle='--', label='y=x')\n",
    "        axes[i, j].set_title(f'{name}')\n",
    "        axes[i, j].set_xlabel('Double mutation')\n",
    "        axes[i, j].set_ylabel('Multiplication of single mutations')\n",
    "        axes[i, j].legend()\n",
    "        axes[i, j].grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/plots_datasets/2std/all_2std_part{num}.svg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Spearman correlation for \"distant\" points (all models, all datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitable_datasets = []\n",
    "cols = ['model']\n",
    "with open('/home/ank24/epistasis_prediction_review/selected_datasets.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        dataset = line.strip()\n",
    "        suitable_datasets.append(dataset)\n",
    "        cols.append(dataset + '_Spearman_all')\n",
    "        cols.append(dataset + '_Spearman_doubles')\n",
    "        cols.append(dataset + '_Spearman_multi')\n",
    "        cols.append(dataset + '_Spearman_distinct_1std')\n",
    "        cols.append(dataset + '_Spearman_distinct_2std')\n",
    "result_all = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "selected_mutations = {}\n",
    "directory = '../data/ProteinGym_subs_apr_2024'\n",
    "\n",
    "for filename in os.listdir(directory): # iterate over datasets\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    dataset = filename.split('.')[0]\n",
    "    if os.path.isfile(file_path) and dataset in suitable_datasets:\n",
    "        df = pd.read_csv(file_path)\n",
    "        indices = {}\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 2: # find 2 mutations\n",
    "                indices[(mutations[0], mutations[1], ind)] = [-1, -1] # indices[mutation 1, mutation 2, index of the pair], and inside we store indices of individual mutations\n",
    "\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 1: # match indices of the 2 mutations to a pair\n",
    "                for key, value in indices.items():\n",
    "                    if key[0] == mutations[0]:\n",
    "                        indices[key][0] = ind\n",
    "                    if key[1] == mutations[0]:\n",
    "                        indices[key][1] = ind\n",
    "\n",
    "        dic_final = {}\n",
    "        for key, value in indices.items():\n",
    "            if value[0] != -1 and value[1] != -1:\n",
    "                dic_final[key] = value\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1)) # minmax scale values\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        selected = []\n",
    "        for key, value in dic_final.items():\n",
    "            ind = key[2]\n",
    "            x.append(df.loc[ind, 'DMS_score_scaled']) # score for a pair\n",
    "            selected.append(key[0] + ':' + key[1])\n",
    "            ind_first = value[0]\n",
    "            ind_second = value[1]\n",
    "            y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled']) # multiplied individuals\n",
    "\n",
    "        # Calculate distances from the line y = x\n",
    "        distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "        # Calculate mean and standard deviation of the distances\n",
    "        mean_distance = np.mean(distances)\n",
    "        std_distance = np.std(distances)\n",
    "        # Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "        threshold = mean_distance + 1 * std_distance\n",
    "        # Identify points that are \"distinct\"\n",
    "        distinct_points = distances > threshold\n",
    "        selected_muts_1 = [element for element, mask in zip(selected, distinct_points.tolist()) if mask] # for 1 std\n",
    "\n",
    "        threshold = mean_distance + 2 * std_distance\n",
    "        distinct_points = distances > threshold\n",
    "        selected_muts_2 = [element for element, mask in zip(selected, distinct_points.tolist()) if mask] # for 2 std\n",
    "        \n",
    "        selected_mutations[dataset] = (selected_muts_1, selected_muts_2)\n",
    "        dfs[dataset] = df# Iterate over all model prediction folders in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spearman(result_all, entry_path, model):\n",
    "    score_columns = []\n",
    "    score_indices = {}\n",
    "    for filename in os.listdir(entry_path): # let's just open 1 file and check if there're several rows with predictions (different num of parameters)\n",
    "        file_path = os.path.join(entry_path, filename)\n",
    "        dataset = filename.split('.')[0]\n",
    "        if dataset in suitable_datasets: \n",
    "            df = dfs[dataset]\n",
    "            df_pred = pd.read_csv(file_path)\n",
    "            for col in df_pred.columns:\n",
    "                if ('mut' not in col) and ('seq' not in col) and ('DMS_score' not in col):\n",
    "                    score_columns.append(col)\n",
    "            break\n",
    "    for score_column in score_columns:\n",
    "        new_row = pd.DataFrame(dict(zip(list(result_all.columns), [model + '_' + score_column] + [None]*(result_all.shape[1] - 1))), index=[0])\n",
    "        result_all = pd.concat([result_all, new_row], ignore_index=True) # SAVE INDICES + SCORE NAMES IN A DICT TO APPEND AFTERWARDS\n",
    "        score_indices[score_column] = result_all.index[-1]\n",
    "    for filename in os.listdir(entry_path): # iterate over datasets\n",
    "        file_path = os.path.join(entry_path, filename)\n",
    "        dataset = filename.split('.')[0]\n",
    "        if dataset in suitable_datasets: \n",
    "            df = dfs[dataset]\n",
    "            df_pred = pd.read_csv(file_path)\n",
    "            if 'mutant' in df_pred.columns:\n",
    "                if 'DMS_score' in df_pred.columns:\n",
    "                    merged_df = df.merge(df_pred, left_on=['mutant', 'DMS_score'], right_on=['mutant', 'DMS_score'])\n",
    "                else:\n",
    "                    merged_df = df.merge(df_pred, left_on='mutant', right_on='mutant')\n",
    "            else:\n",
    "                if 'DMS_score' in df_pred.columns:\n",
    "                    merged_df = df.merge(df_pred, left_on=['mutated_sequence', 'DMS_score'], right_on=['mutated_sequence', 'DMS_score'])\n",
    "                else:\n",
    "                    merged_df = df.merge(df_pred, left_on='mutated_sequence', right_on='mutated_sequence')\n",
    "\n",
    "            for score_column in score_columns: # calculate for all predicted scores\n",
    "                spearman_all = spearmanr(merged_df['DMS_score'], merged_df[score_column])[0]\n",
    "\n",
    "                merged_df['num_mutations'] = merged_df['mutant'].str.split(':').apply(len)\n",
    "\n",
    "                merged_df_doubles = merged_df[merged_df['num_mutations'] == 2]\n",
    "                spearman_doubles = spearmanr(merged_df_doubles['DMS_score'], merged_df_doubles[score_column])[0]\n",
    "\n",
    "                merged_df_multi = merged_df[merged_df['num_mutations'] >= 2]\n",
    "                spearman_multi = spearmanr(merged_df_multi['DMS_score'], merged_df_multi[score_column])[0]\n",
    "                \n",
    "                selected_mutations_1, selected_mutations_2 = selected_mutations[dataset]\n",
    "                merged_df_selected_1 = merged_df[merged_df['mutant'].isin(selected_mutations_1)]\n",
    "                spearman_distinct_1 = spearmanr(merged_df_selected_1['DMS_score'], merged_df_selected_1[score_column])[0]\n",
    "                merged_df_selected_2 = merged_df[merged_df['mutant'].isin(selected_mutations_2)]\n",
    "                spearman_distinct_2 = spearmanr(merged_df_selected_2['DMS_score'], merged_df_selected_2[score_column])[0]\n",
    "\n",
    "                result_all.loc[score_indices[score_column], dataset + '_Spearman_all'] = f\"{spearman_all:.2f}\"\n",
    "                result_all.loc[score_indices[score_column], dataset + '_Spearman_doubles'] = f\"{spearman_doubles:.2f}\"\n",
    "                result_all.loc[score_indices[score_column], dataset + '_Spearman_multi'] = f\"{spearman_multi:.2f}\"\n",
    "                result_all.loc[score_indices[score_column], dataset + '_Spearman_distinct_1std'] = f\"{spearman_distinct_1:.2f}\"\n",
    "                result_all.loc[score_indices[score_column], dataset + '_Spearman_distinct_2std'] = f\"{spearman_distinct_2:.2f}\"\n",
    "    return result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/Predictions'\n",
    "for model in os.listdir(directory): # iterate over models\n",
    "    entry_path = os.path.join(directory, model)\n",
    "    if any(os.path.isdir(os.path.join(entry_path, entry)) for entry in os.listdir(entry_path)): # case when there are subfolders inside a model (different parameter number)\n",
    "        for folder_name in os.listdir(entry_path): # iterate over submodels\n",
    "            folder_path = os.path.join(entry_path, folder_name)\n",
    "            result_all = calculate_spearman(result_all, folder_path, model + '_' + folder_name)\n",
    "    else: # standart case\n",
    "        result_all = calculate_spearman(result_all, entry_path, model)\n",
    "result_all.to_csv('../all_Spearman_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add linreg baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all = pd.read_csv('../all_Spearman_values.csv', dtype=str)\n",
    "result_all.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(zip(['LinearRegression'], [LinearRegression]))\n",
    "indices = dict(zip(['LinearRegression'], [len(result_all)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in suitable_datasets:\n",
    "    df = dfs[dataset]\n",
    "    df['num_mutations'] = df['mutant'].str.split(':').apply(len)\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    max_len = max(len(seq) for seq in df.mutated_sequence)\n",
    "\n",
    "    sequences = list(df[df['mutant'].apply(lambda x: len(x.split(':')) == 1)].mutated_sequence)\n",
    "    \n",
    "    sequences = [list(seq) for seq in sequences]\n",
    "    padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "    padded_array = np.array(padded_sequences)\n",
    "    enc.fit(padded_array)\n",
    "    x_train = enc.transform(padded_array).toarray()\n",
    "    y_train = df[df['mutant'].apply(lambda x: len(x.split(':')) == 1)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    selected_mutations_1, selected_mutations_2 = selected_mutations[dataset]\n",
    "\n",
    "    x_test_doubles = y_test_doubles = x_test_multi = y_test_multi = x_test_1 = y_test_1 = x_test_2 = y_test_2 = None\n",
    "\n",
    "    sequences = df[df['num_mutations'] == 2].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test_doubles = enc.transform(padded_array).toarray()\n",
    "        y_test_doubles = df[df['num_mutations'] == 2].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    sequences = df[df['num_mutations'] >= 2].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test_multi = enc.transform(padded_array).toarray()\n",
    "        y_test_multi = df[df['num_mutations'] >= 2].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    sequences = df[df['mutant'].isin(selected_mutations_1)].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test_1 = enc.transform(padded_array).toarray()\n",
    "        y_test_1 = df[df['mutant'].isin(selected_mutations_1)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    sequences = df[df['mutant'].isin(selected_mutations_2)].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test_2 = enc.transform(padded_array).toarray()\n",
    "        y_test_2 = df[df['mutant'].isin(selected_mutations_2)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    for model in models:\n",
    "        result_all.loc[indices[model], 'model'] = model\n",
    "\n",
    "        model_dataset = models[model]()\n",
    "        model_dataset.fit(x_train, y_train)\n",
    "\n",
    "        sequences = list(df.mutated_sequence)\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test = enc.transform(padded_array).toarray()\n",
    "        y_test = df.DMS_score.values.reshape(-1,1)\n",
    "        y_pred = model_dataset.predict(x_test)\n",
    "        spearman = spearmanr(y_test, y_pred)[0]\n",
    "        result_all.loc[indices[model], dataset + '_Spearman_all'] = spearman\n",
    "\n",
    "        if x_test_doubles is not None:\n",
    "            y_pred_doubles = model_dataset.predict(x_test_doubles)\n",
    "            spearman_doubles = spearmanr(y_test_doubles, y_pred_doubles)[0]\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_doubles'] = f\"{spearman_doubles:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_doubles'] = 0\n",
    "\n",
    "        if x_test_multi is not None:\n",
    "            y_pred = model_dataset.predict(x_test_multi)\n",
    "            spearman = spearmanr(y_test_multi, y_pred)[0]\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_multi'] = f\"{spearman:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_multi'] = 0\n",
    "\n",
    "        if x_test_1 is not None:\n",
    "            y_pred_1 = model_dataset.predict(x_test_1)\n",
    "            spearman_distinct_1 = spearmanr(y_test_1, y_pred_1)[0]\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_distinct_1std'] = f\"{spearman_distinct_1:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_distinct_1std'] = 0\n",
    "\n",
    "        if x_test_2 is not None:\n",
    "            y_pred_2 = model_dataset.predict(x_test_2)\n",
    "            spearman_distinct_2 = spearmanr(y_test_2, y_pred_2)[0]\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_distinct_2std'] = f\"{spearman_distinct_2:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_distinct_2std'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all.to_csv('../all_Spearman_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of Spearman values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitable_datasets = []\n",
    "with open('../selected_datasets.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        dataset = line.strip()\n",
    "        suitable_datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../all_Spearman_values.csv', index_col=1)\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "for dataset in suitable_datasets:\n",
    "    all = np.abs(df[dataset + '_Spearman_all'])\n",
    "    std1 = np.abs(df[dataset + '_Spearman_distinct_1std'])\n",
    "    std2 = np.abs(df[dataset + '_Spearman_distinct_2std'])\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    #plt.figure(figsize=[34,38])\n",
    "    categories = df.index  # Coordinates on the x-axis\n",
    "    x = np.arange(len(categories))  # Positions for the groups\n",
    "    width = 0.2  # Width of the bars\n",
    "    fig, ax = plt.subplots(figsize=(28, 8))\n",
    "    # Plot each set of bars with a specific x offset\n",
    "    ax.bar(x - width, all, width, color='midnightblue', label='All points')\n",
    "    ax.bar(x, std1, width, color=cmap(1), label='Distant points (1 std)')\n",
    "    ax.bar(x + width, std2, width, color=cmap(0), label='Distant points (2 std)')\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xlabel('Model', fontsize=14)\n",
    "    ax.set_ylabel('Spearman correlation', fontsize=14)\n",
    "    ax.set_title(f'Spearman correlations for {dataset}', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.grid(True, axis='y')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.savefig(f'../figures/plots_models/{dataset}.svg', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double/multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../all_Spearman_values.csv', index_col=1)\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "for dataset in suitable_datasets:\n",
    "    doubles = np.abs(df[dataset + '_Spearman_doubles'])\n",
    "    multi = np.abs(df[dataset + '_Spearman_multi'])\n",
    "    std1 = np.abs(df[dataset + '_Spearman_distinct_1std'])\n",
    "    std2 = np.abs(df[dataset + '_Spearman_distinct_2std'])\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    #plt.figure(figsize=[34,38])\n",
    "    categories = df.index  # Coordinates on the x-axis\n",
    "    x = np.arange(len(categories))  # Positions for the groups\n",
    "    width = 0.2  # Width of the bars\n",
    "    fig, ax = plt.subplots(figsize=(28, 8))\n",
    "    # Plot each set of bars with a specific x offset\n",
    "    ax.bar(x - 1.5*width, doubles, width, color=cmap(6), label='Double mutations')\n",
    "    ax.bar(x - width/2, multi, width, color=cmap(7), label='Multi (2+) mutations')\n",
    "    ax.bar(x + width/2, std1, width, color=cmap(1), label='Distant points (1 std)')\n",
    "    ax.bar(x + 1.5*width, std2, width, color=cmap(0), label='Distant points (2 std)')\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xlabel('Model', fontsize=14)\n",
    "    ax.set_ylabel('Spearman correlation', fontsize=14)\n",
    "    ax.set_title(f'Spearman correlations for {dataset}', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.grid(True, axis='y')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.savefig(f'../figures/plots_models/{dataset}_multi.svg', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A4_HUMAN_Seuma_2022_Spearman_distinct_2std               0\n",
      "AMFR_HUMAN_Tsuboyama_2023_4G3O_Spearman_distinct_2std    0\n",
      "BBC1_YEAST_Tsuboyama_2023_1TG0_Spearman_distinct_2std    0\n",
      "BCHB_CHLTE_Tsuboyama_2023_2KRU_Spearman_distinct_2std    0\n",
      "CAPSD_AAV2S_Sinai_2021_Spearman_distinct_2std            0\n",
      "                                                        ..\n",
      "UBR5_HUMAN_Tsuboyama_2023_1I2T_Spearman_distinct_2std    0\n",
      "VILI_CHICK_Tsuboyama_2023_1YU5_Spearman_distinct_2std    0\n",
      "YAIA_ECOLI_Tsuboyama_2023_2KVT_Spearman_distinct_2std    0\n",
      "YAP1_HUMAN_Araya_2012_Spearman_distinct_2std             0\n",
      "YNZC_BACSU_Tsuboyama_2023_2JVD_Spearman_distinct_2std    0\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(np.isinf(df_slice).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def rename_columns(col, num):\n",
    "    parts = col.split('_')  # Split by '_'\n",
    "    return '_'.join(parts[:len(parts) - num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = ['_Spearman_all', '_Spearman_doubles', '_Spearman_multi', '_Spearman_distinct_1std', '_Spearman_distinct_2std']\n",
    "cnt = 0\n",
    "for plot in plots:\n",
    "    df_slice = np.abs(df.filter(like=plot))\n",
    "    if cnt < 3:\n",
    "        df_slice.columns = [rename_columns(col, 2) for col in df_slice.columns]\n",
    "    else:\n",
    "        df_slice.columns = [rename_columns(col, 3) for col in df_slice.columns]\n",
    "    cnt += 1\n",
    "    df_slice.fillna(0, inplace=True)\n",
    "    plt.figure(figsize=[28,8])\n",
    "    sns.violinplot(df_slice)\n",
    "    plt.xlabel('Datasets', fontsize=14)\n",
    "    plt.ylabel('Spearman correlation', fontsize=14)\n",
    "    plt.title(f'Spearman correlation of all methods ({plot.split('_')[-1]} points)', fontsize=16)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.savefig(f'../figures/violin_plots/{plot[1:]}.svg', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
