{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/wibicomfs/STBS/anastasia/epistasis_prediction_review/data/ProteinGym_subs_apr_2024'\n",
    "suitable_datasets = []\n",
    "cnt = 0\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'mutant' in df.columns:\n",
    "            cnt += 1\n",
    "            mutations = df['mutant']\n",
    "            for mut in mutations:\n",
    "                if len(mut.split(':')) > 1:\n",
    "                    suitable_datasets.append(file_path)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the file path\n",
    "# file_path = '../selected_datasets.txt'\n",
    "\n",
    "# # Open the file in write mode and write the strings line by line\n",
    "# with open(file_path, 'w') as file:\n",
    "#     for string in suitable_datasets:\n",
    "#         file.write(string.split('/')[-1].split('.')[0] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = []\n",
    "for dataset in suitable_datasets:\n",
    "    name = dataset.split('/')[-1].split('.')[0]\n",
    "    df = pd.read_csv(dataset)\n",
    "    df['num_mutations'] = df['mutant'].str.split(':').apply(len)\n",
    "    max_mutation = df['num_mutations'].max()\n",
    "    mutations.append(max_mutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mutations, counts = np.unique(mutations, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=[10, 4])\n",
    "plt.bar(unique_mutations, counts, align='center', width=0.8)\n",
    "plt.xticks(unique_mutations)\n",
    "plt.xlabel(\"Maximal number of mutations\")\n",
    "plt.ylabel(\"Number of datasets\")\n",
    "plt.title(\"Distribution of maximal number of mutations in datasets\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../figures/paper/1a_mutations_distribution.png', bbox_inches='tight', dpi=300)\n",
    "plt.savefig(f'../figures/paper/1a_mutations_distribution.pdf', bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epistasis plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"data/ProteinGym_subs_apr_2024/GFP_AEQVI_Sarkisyan_2016.csv\"\n",
    "df = pd.read_csv(dataset)\n",
    "indices = {}\n",
    "for ind, row in df.iterrows():\n",
    "    mutations = row['mutant'].split(':')\n",
    "    if len(mutations) == 2:\n",
    "        indices[(mutations[0], mutations[1], ind)] = [-1, -1]\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    mutations = row['mutant'].split(':')\n",
    "    if len(mutations) == 1:\n",
    "        for key, value in indices.items():\n",
    "            if key[0] == mutations[0]:\n",
    "                indices[key][0] = ind\n",
    "            if key[1] == mutations[0]:\n",
    "                indices[key][1] = ind\n",
    "\n",
    "dic_final = {}\n",
    "for key, value in indices.items():\n",
    "    if value[0] != -1 and value[1] != -1:\n",
    "        dic_final[key] = value\n",
    "\n",
    "#df['DMS_score_log'] = np.log1p(df['DMS_score'])\n",
    "scaler = MinMaxScaler()\n",
    "df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1))\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "selected = []\n",
    "for key, value in dic_final.items():\n",
    "    ind = key[2]\n",
    "    x.append(df.loc[ind, 'DMS_score_scaled'])\n",
    "    selected.append(key[0] + ':' + key[1])\n",
    "    ind_first = value[0]\n",
    "    ind_second = value[1]\n",
    "    y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled'])\n",
    "\n",
    "# Calculate distances from the line y = x\n",
    "distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "# Calculate mean and standard deviation of the distances\n",
    "mean_distance = np.mean(distances)\n",
    "std_distance = np.std(distances)\n",
    "# Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "threshold = mean_distance + 2 * std_distance\n",
    "# Identify points that are \"distinct\"\n",
    "distinct_points = distances > threshold\n",
    "distinct_x = np.array(x)[distinct_points.tolist()]\n",
    "distinct_y = np.array(y)[distinct_points.tolist()]\n",
    "selected_mutations = [element for element, mask in zip(selected, distinct_points.tolist()) if mask]\n",
    "\n",
    "cmap = plt.get_cmap('Paired')\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.scatter(x, y, color=cmap(1), alpha=0.8, label='near points')\n",
    "plt.scatter(distinct_x, distinct_y, color=cmap(0), alpha=0.8, label='distinct points')\n",
    "plt.plot([0, 1], [0, 1], color='grey', alpha=0.8, linestyle='--', label='y=x')\n",
    "plt.xlabel(r'Effect of the combination of mutations $f(m_1, \\dots, m_k)$', fontsize=14)\n",
    "plt.ylabel(r'Product of individual effects $f(m_1)\\cdot \\dots \\cdot f(m_k)$', fontsize=14)\n",
    "plt.title('Example of a dataset with epistasis (GFP from A. Victoria)', fontsize=16)\n",
    "plt.legend(prop={'size': 14})\n",
    "plt.grid(True)\n",
    "plt.savefig(f'../figures/paper/1c_plot.png', dpi=300)\n",
    "plt.savefig(f'../figures/paper/1c_plot.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"data/ProteinGym_subs_apr_2024/GFP_AEQVI_Sarkisyan_2016.csv\",\n",
    "            \"data/ProteinGym_subs_apr_2024/D7PM05_CLYGR_Somermeyer_2022.csv\",\n",
    "            \"data/ProteinGym_subs_apr_2024/F7YBW8_MESOW_Aakre_2015.csv\"]\n",
    "titles = ['GFP from Aequorea victoria',\n",
    "          'GFP from Clytia gregaria',\n",
    "          'Addiction module antidote protein from Mesorhizobium opportunistum']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    df = pd.read_csv(dataset)\n",
    "    indices = {}\n",
    "    for ind, row in df.iterrows():\n",
    "        mutations = row['mutant'].split(':')\n",
    "        if len(mutations) == 2:\n",
    "            indices[(mutations[0], mutations[1], ind)] = [-1, -1]\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        mutations = row['mutant'].split(':')\n",
    "        if len(mutations) == 1:\n",
    "            for key, value in indices.items():\n",
    "                if key[0] == mutations[0]:\n",
    "                    indices[key][0] = ind\n",
    "                if key[1] == mutations[0]:\n",
    "                    indices[key][1] = ind\n",
    "\n",
    "    dic_final = {}\n",
    "    for key, value in indices.items():\n",
    "        if value[0] != -1 and value[1] != -1:\n",
    "            dic_final[key] = value\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    selected = []\n",
    "    for key, value in dic_final.items():\n",
    "        ind = key[2]\n",
    "        x.append(df.loc[ind, 'DMS_score_scaled'])\n",
    "        selected.append(key[0] + ':' + key[1])\n",
    "        ind_first = value[0]\n",
    "        ind_second = value[1]\n",
    "        y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled'])\n",
    "\n",
    "    distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "    mean_distance = np.mean(distances)\n",
    "    std_distance = np.std(distances)\n",
    "    threshold = mean_distance + 2 * std_distance\n",
    "    distinct_points = distances > threshold\n",
    "    distinct_x = np.array(x)[distinct_points.tolist()]\n",
    "    distinct_y = np.array(y)[distinct_points.tolist()]\n",
    "    selected_mutations = [element for element, mask in zip(selected, distinct_points.tolist()) if mask]\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "\n",
    "    # Bar plot for counts of x and distinct_x\n",
    "    counts = [len(x), len(distinct_x)]\n",
    "    bar_labels = [len(x), len(distinct_x)]\n",
    "    bar_colors = [cmap(1), cmap(0)]\n",
    "    # Position the bar plot in the right bottom corner\n",
    "    inset_ax = axes[i].inset_axes([0.75, 0.05, 0.2, 0.2])\n",
    "    inset_ax.bar(range(len(bar_labels)), counts, color=bar_colors, alpha=0.8)\n",
    "    inset_ax.set_xticks(range(len(bar_labels)))\n",
    "    inset_ax.set_xticklabels(bar_labels, fontsize=10)\n",
    "    inset_ax.set_title('Near vs distinct', fontsize=10)\n",
    "    inset_ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "    axes[i].scatter(x, y, color=cmap(1), alpha=0.8, label='near points')\n",
    "    axes[i].scatter(distinct_x, distinct_y, color=cmap(0), alpha=0.8, label='distinct points')\n",
    "    axes[i].plot([0, 1], [0, 1], color='grey', alpha=0.8, linestyle='--', label='y=x')\n",
    "    axes[i].set_xlabel(r'Effect of the combination of mutations $f(m_1, \\dots, m_k)$', fontsize=14)\n",
    "    axes[i].set_ylabel(r'Product of individual effects $f(m_1)\\cdot \\dots \\cdot f(m_k)$', fontsize=14)\n",
    "    axes[i].set_title(titles[i], fontsize=16)\n",
    "    axes[i].legend(prop={'size': 14})\n",
    "    axes[i].grid(True)\n",
    "plt.savefig(f'figures/paper/1d_bar.png', dpi=300)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "#plt.savefig(f'../figures/paper/1c_plot.png', dpi=300)\n",
    "#plt.savefig(f'../figures/paper/1c_plot.pdf')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"data/ProteinGym_subs_apr_2024/GFP_AEQVI_Sarkisyan_2016.csv\",\n",
    "            \"data/ProteinGym_subs_apr_2024/D7PM05_CLYGR_Somermeyer_2022.csv\",\n",
    "            \"data/ProteinGym_subs_apr_2024/F7YBW8_MESOW_Aakre_2015.csv\"]\n",
    "titles = ['GFP from Aequorea victoria',\n",
    "          'GFP from Clytia gregaria',\n",
    "          'Addiction module antidote protein from Mesorhizobium opportunistum']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    df = pd.read_csv(dataset)\n",
    "    indices = {}\n",
    "    for ind, row in df.iterrows():\n",
    "        mutations = row['mutant'].split(':')\n",
    "        if len(mutations) == 2:\n",
    "            indices[(mutations[0], mutations[1], ind)] = [-1, -1]\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        mutations = row['mutant'].split(':')\n",
    "        if len(mutations) == 1:\n",
    "            for key, value in indices.items():\n",
    "                if key[0] == mutations[0]:\n",
    "                    indices[key][0] = ind\n",
    "                if key[1] == mutations[0]:\n",
    "                    indices[key][1] = ind\n",
    "\n",
    "    dic_final = {}\n",
    "    for key, value in indices.items():\n",
    "        if value[0] != -1 and value[1] != -1:\n",
    "            dic_final[key] = value\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    selected = []\n",
    "    for key, value in dic_final.items():\n",
    "        ind = key[2]\n",
    "        x.append(df.loc[ind, 'DMS_score_scaled'])\n",
    "        selected.append(key[0] + ':' + key[1])\n",
    "        ind_first = value[0]\n",
    "        ind_second = value[1]\n",
    "        y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled'])\n",
    "\n",
    "    distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "    mean_distance = np.mean(distances)\n",
    "    std_distance = np.std(distances)\n",
    "    threshold = mean_distance + 1 * std_distance\n",
    "    distinct_points = distances > threshold\n",
    "    distinct_x = np.array(x)[distinct_points.tolist()]\n",
    "    distinct_y = np.array(y)[distinct_points.tolist()]\n",
    "    selected_mutations = [element for element, mask in zip(selected, distinct_points.tolist()) if mask]\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "\n",
    "    # Bar plot for counts of x and distinct_x\n",
    "    counts = [len(x), len(distinct_x)]\n",
    "    bar_labels = [len(x), len(distinct_x)]\n",
    "    bar_colors = [cmap(1), cmap(0)]\n",
    "    # Position the bar plot in the right bottom corner\n",
    "    inset_ax = axes[i].inset_axes([0.75, 0.05, 0.2, 0.2])\n",
    "    inset_ax.bar(range(len(bar_labels)), counts, color=bar_colors, alpha=0.8)\n",
    "    inset_ax.set_xticks(range(len(bar_labels)))\n",
    "    inset_ax.set_xticklabels(bar_labels, fontsize=10)\n",
    "    inset_ax.set_title('Near vs distinct', fontsize=10)\n",
    "    inset_ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "    axes[i].scatter(x, y, color=cmap(1), alpha=0.8, label='near points')\n",
    "    axes[i].scatter(distinct_x, distinct_y, color=cmap(0), alpha=0.8, label='distinct points')\n",
    "    axes[i].plot([0, 1], [0, 1], color='grey', alpha=0.8, linestyle='--', label='y=x')\n",
    "    axes[i].set_xlabel(r'Effect of the combination of mutations $f(m_1, \\dots, m_k)$', fontsize=14)\n",
    "    axes[i].set_ylabel(r'Product of individual effects $f(m_1)\\cdot \\dots \\cdot f(m_k)$', fontsize=14)\n",
    "    axes[i].set_title(titles[i], fontsize=16)\n",
    "    axes[i].legend(prop={'size': 14})\n",
    "    axes[i].grid(True)\n",
    "plt.savefig(f'figures/paper/supp2_bar.png', dpi=300)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "#plt.savefig(f'../figures/paper/1c_plot.png', dpi=300)\n",
    "#plt.savefig(f'../figures/paper/1c_plot.pdf')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in suitable_datasets:\n",
    "    name = dataset.split('/')[-1].split('.')[0]\n",
    "    df = pd.read_csv(dataset)\n",
    "    indices = {}\n",
    "    for ind, row in df.iterrows():\n",
    "        mutations = row['mutant'].split(':')\n",
    "        if len(mutations) == 2:\n",
    "            indices[(mutations[0], mutations[1], ind)] = [-1, -1]\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        mutations = row['mutant'].split(':')\n",
    "        if len(mutations) == 1:\n",
    "            for key, value in indices.items():\n",
    "                if key[0] == mutations[0]:\n",
    "                    indices[key][0] = ind\n",
    "                if key[1] == mutations[0]:\n",
    "                    indices[key][1] = ind\n",
    "\n",
    "    dic_final = {}\n",
    "    for key, value in indices.items():\n",
    "        if value[0] != -1 and value[1] != -1:\n",
    "            dic_final[key] = value\n",
    "\n",
    "    #df['DMS_score_log'] = np.log1p(df['DMS_score'])\n",
    "    scaler = MinMaxScaler()\n",
    "    df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    selected = []\n",
    "    for key, value in dic_final.items():\n",
    "        ind = key[2]\n",
    "        x.append(df.loc[ind, 'DMS_score_scaled'])\n",
    "        selected.append(key[0] + ':' + key[1])\n",
    "        ind_first = value[0]\n",
    "        ind_second = value[1]\n",
    "        y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled'])\n",
    "\n",
    "    # Calculate distances from the line y = x\n",
    "    distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "    # Calculate mean and standard deviation of the distances\n",
    "    mean_distance = np.mean(distances)\n",
    "    std_distance = np.std(distances)\n",
    "    # Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "    threshold = mean_distance + 2 * std_distance\n",
    "    # Identify points that are \"distinct\"\n",
    "    distinct_points = distances > threshold\n",
    "    distinct_x = np.array(x)[distinct_points.tolist()]\n",
    "    distinct_y = np.array(y)[distinct_points.tolist()]\n",
    "    selected_mutations = [element for element, mask in zip(selected, distinct_points.tolist()) if mask]\n",
    "\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    plt.figure(figsize=[8,8])\n",
    "    plt.scatter(x, y, color=cmap(1), alpha=0.8, label='near points')\n",
    "    plt.scatter(distinct_x, distinct_y, color=cmap(0), alpha=0.8, label='distinct points')\n",
    "    plt.plot([0, 1], [0, 1], color='grey', alpha=0.8, linestyle='--', label='y=x')\n",
    "    plt.xlabel('Double mutation', fontsize=14)\n",
    "    plt.ylabel('Multiplication of single mutations', fontsize=14)\n",
    "    plt.title(f'Measured fluorescence values {name}', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'../figures/plots_datasets/2std/{name}.svg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "subsets = []\n",
    "start = 0\n",
    "while start != 60:\n",
    "    subsets.append(suitable_datasets[start:start+12])\n",
    "    start += 12\n",
    "subsets.append(suitable_datasets[start:])\n",
    "for num in range(len(subsets)):\n",
    "    subset = subsets[num]\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20, 30))\n",
    "    for index in range(len(subset)):\n",
    "        dataset = subset[index]\n",
    "        name = dataset.split('/')[-1].split('.')[0]\n",
    "        df = pd.read_csv(dataset)\n",
    "        indices = {}\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 2:\n",
    "                indices[(mutations[0], mutations[1], ind)] = [-1, -1]\n",
    "\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 1:\n",
    "                for key, value in indices.items():\n",
    "                    if key[0] == mutations[0]:\n",
    "                        indices[key][0] = ind\n",
    "                    if key[1] == mutations[0]:\n",
    "                        indices[key][1] = ind\n",
    "\n",
    "        dic_final = {}\n",
    "        for key, value in indices.items():\n",
    "            if value[0] != -1 and value[1] != -1:\n",
    "                dic_final[key] = value\n",
    "\n",
    "        #df['DMS_score_log'] = np.log1p(df['DMS_score'])\n",
    "        scaler = MinMaxScaler()\n",
    "        df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1))\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        selected = []\n",
    "        for key, value in dic_final.items():\n",
    "            ind = key[2]\n",
    "            x.append(df.loc[ind, 'DMS_score_scaled'])\n",
    "            selected.append(key[0] + ':' + key[1])\n",
    "            ind_first = value[0]\n",
    "            ind_second = value[1]\n",
    "            y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled'])\n",
    "\n",
    "        # Calculate distances from the line y = x\n",
    "        distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "        # Calculate mean and standard deviation of the distances\n",
    "        mean_distance = np.mean(distances)\n",
    "        std_distance = np.std(distances)\n",
    "        # Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "        threshold = mean_distance + 1 * std_distance\n",
    "        # Identify points that are \"distinct\"\n",
    "        distinct_points = distances > threshold\n",
    "        distinct_x = np.array(x)[distinct_points.tolist()]\n",
    "        distinct_y = np.array(y)[distinct_points.tolist()]\n",
    "        selected_mutations = [element for element, mask in zip(selected, distinct_points.tolist()) if mask]\n",
    "\n",
    "        i = index // 3\n",
    "        j = index % 3\n",
    "        cmap = plt.get_cmap('Paired')\n",
    "        axes[i, j].scatter(x, y, color=cmap(1), alpha=0.8, label='near points')\n",
    "        axes[i, j].scatter(distinct_x, distinct_y, color=cmap(0), alpha=0.8, label='distinct points')\n",
    "        axes[i, j].plot([0, 1], [0, 1], color='grey', alpha=0.8, linestyle='--', label='y=x')\n",
    "        axes[i, j].set_title(f'{name}')\n",
    "        axes[i, j].set_xlabel('Double mutation')\n",
    "        axes[i, j].set_ylabel('Multiplication of single mutations')\n",
    "        axes[i, j].legend()\n",
    "        axes[i, j].grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/plots_datasets/1std/all_1std_part{num}.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "subsets = []\n",
    "start = 0\n",
    "while start != 60:\n",
    "    subsets.append(suitable_datasets[start:start+12])\n",
    "    start += 12\n",
    "subsets.append(suitable_datasets[start:])\n",
    "for num in range(len(subsets)):\n",
    "    subset = subsets[num]\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(20, 30))\n",
    "    for index in range(len(subset)):\n",
    "        dataset = subset[index]\n",
    "        name = dataset.split('/')[-1].split('.')[0]\n",
    "        df = pd.read_csv(dataset)\n",
    "        indices = {}\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 2:\n",
    "                indices[(mutations[0], mutations[1], ind)] = [-1, -1]\n",
    "\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 1:\n",
    "                for key, value in indices.items():\n",
    "                    if key[0] == mutations[0]:\n",
    "                        indices[key][0] = ind\n",
    "                    if key[1] == mutations[0]:\n",
    "                        indices[key][1] = ind\n",
    "\n",
    "        dic_final = {}\n",
    "        for key, value in indices.items():\n",
    "            if value[0] != -1 and value[1] != -1:\n",
    "                dic_final[key] = value\n",
    "\n",
    "        #df['DMS_score_log'] = np.log1p(df['DMS_score'])\n",
    "        scaler = MinMaxScaler()\n",
    "        df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1))\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        selected = []\n",
    "        for key, value in dic_final.items():\n",
    "            ind = key[2]\n",
    "            x.append(df.loc[ind, 'DMS_score_scaled'])\n",
    "            selected.append(key[0] + ':' + key[1])\n",
    "            ind_first = value[0]\n",
    "            ind_second = value[1]\n",
    "            y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled'])\n",
    "\n",
    "        # Calculate distances from the line y = x\n",
    "        distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "        # Calculate mean and standard deviation of the distances\n",
    "        mean_distance = np.mean(distances)\n",
    "        std_distance = np.std(distances)\n",
    "        # Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "        threshold = mean_distance + 2 * std_distance\n",
    "        # Identify points that are \"distinct\"\n",
    "        distinct_points = distances > threshold\n",
    "        distinct_x = np.array(x)[distinct_points.tolist()]\n",
    "        distinct_y = np.array(y)[distinct_points.tolist()]\n",
    "        selected_mutations = [element for element, mask in zip(selected, distinct_points.tolist()) if mask]\n",
    "\n",
    "        i = index // 3\n",
    "        j = index % 3\n",
    "        cmap = plt.get_cmap('Paired')\n",
    "\n",
    "\n",
    "        # Bar plot for counts of x and distinct_x\n",
    "        counts = [len(x), len(distinct_x)]\n",
    "        bar_labels = [len(x), len(distinct_x)]\n",
    "        bar_colors = [cmap(1), cmap(0)]\n",
    "        # Position the bar plot in the right bottom corner\n",
    "        inset_ax = axes[i, j].inset_axes([0.75, 0.05, 0.2, 0.2])\n",
    "        inset_ax.bar(range(len(bar_labels)), counts, color=bar_colors, alpha=0.8)\n",
    "        inset_ax.set_xticks(range(len(bar_labels)))\n",
    "        inset_ax.set_xticklabels(bar_labels, fontsize=10)\n",
    "        inset_ax.set_title('Near vs distinct', fontsize=10)\n",
    "        inset_ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "        axes[i, j].scatter(x, y, color=cmap(1), alpha=0.8, label='near points')\n",
    "        axes[i, j].scatter(distinct_x, distinct_y, color=cmap(0), alpha=0.8, label='distinct points')\n",
    "        axes[i, j].plot([0, 1], [0, 1], color='grey', alpha=0.8, linestyle='--', label='y=x')\n",
    "        axes[i, j].set_title(f'{name}')\n",
    "        axes[i, j].set_xlabel('Double mutation')\n",
    "        axes[i, j].set_ylabel('Multiplication of single mutations')\n",
    "        axes[i, j].legend()\n",
    "        axes[i, j].grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/paper/supp1_part{num}.png', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Spearman correlation for \"distant\" points (all models, all datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitable_datasets = []\n",
    "cols = ['model']\n",
    "with open('/home/ank24/epistasis_prediction_review/selected_datasets.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        dataset = line.strip()\n",
    "        suitable_datasets.append(dataset)\n",
    "        cols.append(dataset + '_all')\n",
    "        cols.append(dataset + '_1std')\n",
    "        cols.append(dataset + '_2std')\n",
    "result_all = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dotplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D7PM05_CLYGR_Somermeyer_2022\n",
      "F7YBW8_MESOW_Aakre_2015\n",
      "GFP_AEQVI_Sarkisyan_2016\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "selected_mutations = {}\n",
    "directory = 'data/ProteinGym_subs_apr_2024'\n",
    "\n",
    "for filename in ['D7PM05_CLYGR_Somermeyer_2022.csv',\n",
    "                'F7YBW8_MESOW_Aakre_2015.csv',\n",
    "                'GFP_AEQVI_Sarkisyan_2016.csv']: # iterate over datasets\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    dataset = filename.split('.')[0]\n",
    "    print(dataset)\n",
    "    if os.path.isfile(file_path) and dataset in suitable_datasets:\n",
    "        df = pd.read_csv(file_path)\n",
    "        indices = {}\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 2: # find 2 mutations\n",
    "                indices[(mutations[0], mutations[1], ind)] = [-1, -1] # indices[mutation 1, mutation 2, index of the pair], and inside we store indices of individual mutations\n",
    "\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 1: # match indices of the 2 mutations to a pair\n",
    "                for key, value in indices.items():\n",
    "                    if key[0] == mutations[0]:\n",
    "                        indices[key][0] = ind\n",
    "                    if key[1] == mutations[0]:\n",
    "                        indices[key][1] = ind\n",
    "\n",
    "        dic_final = {}\n",
    "        for key, value in indices.items():\n",
    "            if value[0] != -1 and value[1] != -1:\n",
    "                dic_final[key] = value\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1)) # minmax scale values\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        selected = []\n",
    "        for key, value in dic_final.items():\n",
    "            ind = key[2]\n",
    "            x.append(df.loc[ind, 'DMS_score_scaled']) # score for a pair\n",
    "            selected.append(key[0] + ':' + key[1])\n",
    "            ind_first = value[0]\n",
    "            ind_second = value[1]\n",
    "            y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled']) # multiplied individuals\n",
    "\n",
    "        # Calculate distances from the line y = x\n",
    "        distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "        # Calculate mean and standard deviation of the distances\n",
    "        mean_distance = np.mean(distances)\n",
    "        std_distance = np.std(distances)\n",
    "        # Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "        threshold = mean_distance + 1 * std_distance\n",
    "        # Identify points that are \"distinct\"\n",
    "        distinct_points = distances > threshold\n",
    "        selected_muts_1 = [element for element, mask in zip(selected, distinct_points.tolist()) if mask] # for 1 std\n",
    "\n",
    "        threshold = mean_distance + 2 * std_distance\n",
    "        distinct_points = distances > threshold\n",
    "        selected_muts_2 = [element for element, mask in zip(selected, distinct_points.tolist()) if mask] # for 2 std\n",
    "        \n",
    "        selected_mutations[dataset] = (selected_muts_1, selected_muts_2)\n",
    "        dfs[dataset] = df# Iterate over all model prediction folders in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spearman(result_all, entry_path, model):\n",
    "    score_columns = []\n",
    "    score_indices = {}\n",
    "    for filename in ['D7PM05_CLYGR_Somermeyer_2022.csv',\n",
    "                'F7YBW8_MESOW_Aakre_2015.csv',\n",
    "                'GFP_AEQVI_Sarkisyan_2016.csv']: # let's just open 1 file and check if there're several rows with predictions (different num of parameters)\n",
    "        file_path = os.path.join(entry_path, filename)\n",
    "        dataset = filename.split('.')[0]\n",
    "        if dataset in suitable_datasets: \n",
    "            df = dfs[dataset]\n",
    "            df_pred = pd.read_csv(file_path)\n",
    "            for col in df_pred.columns:\n",
    "                if ('mut' not in col) and ('seq' not in col) and ('DMS_score' not in col):\n",
    "                    score_columns.append(col)\n",
    "            break\n",
    "    for score_column in score_columns:\n",
    "        new_row = pd.DataFrame(dict(zip(list(result_all.columns), [model + '_' + score_column] + [None]*(result_all.shape[1] - 1))), index=[0])\n",
    "        result_all = pd.concat([result_all, new_row], ignore_index=True) # SAVE INDICES + SCORE NAMES IN A DICT TO APPEND AFTERWARDS\n",
    "        score_indices[score_column] = result_all.index[-1]\n",
    "    for filename in ['D7PM05_CLYGR_Somermeyer_2022.csv',\n",
    "                'F7YBW8_MESOW_Aakre_2015.csv',\n",
    "                'GFP_AEQVI_Sarkisyan_2016.csv']: # iterate over datasets\n",
    "        file_path = os.path.join(entry_path, filename)\n",
    "        dataset = filename.split('.')[0]\n",
    "        if dataset in suitable_datasets: \n",
    "            df = dfs[dataset]\n",
    "            df_pred = pd.read_csv(file_path)\n",
    "            if 'mutant' in df_pred.columns:\n",
    "                if 'DMS_score' in df_pred.columns:\n",
    "                    merged_df = df.merge(df_pred, left_on=['mutant', 'DMS_score'], right_on=['mutant', 'DMS_score'])\n",
    "                else:\n",
    "                    merged_df = df.merge(df_pred, left_on='mutant', right_on='mutant')\n",
    "            else:\n",
    "                if 'DMS_score' in df_pred.columns:\n",
    "                    merged_df = df.merge(df_pred, left_on=['mutated_sequence', 'DMS_score'], right_on=['mutated_sequence', 'DMS_score'])\n",
    "                else:\n",
    "                    merged_df = df.merge(df_pred, left_on='mutated_sequence', right_on='mutated_sequence')\n",
    "\n",
    "            for score_column in score_columns: # calculate for all predicted scores\n",
    "                spearman_all = spearmanr(merged_df['DMS_score'], merged_df[score_column])[0]\n",
    "\n",
    "                merged_df['num_mutations'] = merged_df['mutant'].str.split(':').apply(len)\n",
    "                \n",
    "                selected_mutations_1, selected_mutations_2 = selected_mutations[dataset]\n",
    "                merged_df_selected_1 = merged_df[merged_df['mutant'].isin(selected_mutations_1)]\n",
    "                spearman_distinct_1 = spearmanr(merged_df_selected_1['DMS_score'], merged_df_selected_1[score_column])[0]\n",
    "                merged_df_selected_2 = merged_df[merged_df['mutant'].isin(selected_mutations_2)]\n",
    "                spearman_distinct_2 = spearmanr(merged_df_selected_2['DMS_score'], merged_df_selected_2[score_column])[0]\n",
    "\n",
    "                plt.figure(figsize=[9, 9])\n",
    "                plt.plot(merged_df_selected_2['DMS_score'], merged_df_selected_2[score_column], 'ok', alpha=0.5)\n",
    "                plt.xlabel('True values', fontsize=15)\n",
    "                plt.ylabel('Predicted values', fontsize=15)\n",
    "                plt.title(f'{dataset}. Spearman R = {spearman_distinct_2:.2f}', fontsize=15)\n",
    "                plt.savefig(f'figures/dotplots/{dataset}/{result_all.loc[result_all.index[-1], 'model']}.png')\n",
    "                plt.close()\n",
    "\n",
    "                result_all.loc[score_indices[score_column], dataset + '_all'] = f\"{spearman_all:.2f}\"\n",
    "                result_all.loc[score_indices[score_column], dataset + '_1std'] = f\"{spearman_distinct_1:.2f}\"\n",
    "                result_all.loc[score_indices[score_column], dataset + '_2std'] = f\"{spearman_distinct_2:.2f}\"\n",
    "    return result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/zero_shot_substitutions_scores'\n",
    "for model in os.listdir(directory): # iterate over models\n",
    "    entry_path = os.path.join(directory, model)\n",
    "    if any(os.path.isdir(os.path.join(entry_path, entry)) for entry in os.listdir(entry_path)): # case when there are subfolders inside a model (different parameter number)\n",
    "        for folder_name in os.listdir(entry_path): # iterate over submodels\n",
    "            folder_path = os.path.join(entry_path, folder_name)\n",
    "            result_all = calculate_spearman(result_all, folder_path, model + '_' + folder_name)\n",
    "    else: # standart case\n",
    "        result_all = calculate_spearman(result_all, entry_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(zip(['LinearRegression'], [LinearRegression]))\n",
    "for dataset in ['D7PM05_CLYGR_Somermeyer_2022',\n",
    "                'F7YBW8_MESOW_Aakre_2015',\n",
    "                'GFP_AEQVI_Sarkisyan_2016']:\n",
    "    df = dfs[dataset]\n",
    "    df['num_mutations'] = df['mutant'].str.split(':').apply(len)\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    max_len = max(len(seq) for seq in df.mutated_sequence)\n",
    "\n",
    "    sequences = list(df[df['mutant'].apply(lambda x: len(x.split(':')) == 1)].mutated_sequence)\n",
    "    \n",
    "    sequences = [list(seq) for seq in sequences]\n",
    "    padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "    padded_array = np.array(padded_sequences)\n",
    "    enc.fit(padded_array)\n",
    "    x_train = enc.transform(padded_array).toarray()\n",
    "    y_train = df[df['mutant'].apply(lambda x: len(x.split(':')) == 1)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    selected_mutations_1, selected_mutations_2 = selected_mutations[dataset]\n",
    "\n",
    "    x_test_1 = y_test_1 = x_test_2 = y_test_2 = None\n",
    "\n",
    "    sequences = df[df['mutant'].isin(selected_mutations_1)].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test_1 = enc.transform(padded_array).toarray()\n",
    "        y_test_1 = df[df['mutant'].isin(selected_mutations_1)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    sequences = df[df['mutant'].isin(selected_mutations_2)].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test_2 = enc.transform(padded_array).toarray()\n",
    "        y_test_2 = df[df['mutant'].isin(selected_mutations_2)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    for model in models:\n",
    "        model_dataset = models[model]()\n",
    "        model_dataset.fit(x_train, y_train)\n",
    "\n",
    "        sequences = list(df.mutated_sequence)\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test = enc.transform(padded_array).toarray()\n",
    "        y_test = df.DMS_score.values.reshape(-1,1)\n",
    "        y_pred = model_dataset.predict(x_test)\n",
    "        spearman = spearmanr(y_test, y_pred)[0]\n",
    "\n",
    "        if x_test_1 is not None:\n",
    "            y_pred_1 = model_dataset.predict(x_test_1)\n",
    "            spearman_distinct_1 = spearmanr(y_test_1, y_pred_1)[0]\n",
    "\n",
    "        if x_test_2 is not None:\n",
    "            y_pred_2 = model_dataset.predict(x_test_2)\n",
    "            spearman_distinct_2 = spearmanr(y_test_2, y_pred_2)[0]\n",
    "            plt.figure(figsize=[9, 9])\n",
    "            plt.plot(y_test_2, y_pred_2, 'ok', alpha=0.5)\n",
    "            plt.xlabel('True values', fontsize=15)\n",
    "            plt.ylabel('Predicted values', fontsize=15)\n",
    "            plt.title(f'{dataset}. Spearman R = {spearman_distinct_2:.2f}', fontsize=15)\n",
    "            plt.savefig(f'figures/dotplots/{dataset}/LinearRegression.png')\n",
    "            plt.close()\n",
    "\n",
    "            if dataset == 'D7PM05_CLYGR_Somermeyer_2022':\n",
    "                table = df[df['mutant'].isin(selected_mutations_2)][['mutant', 'DMS_score']]    \n",
    "                table['predicted'] = y_pred_2\n",
    "                x1, y1 = 1.5, 1.5\n",
    "                x2, y2 = 3.5, 4\n",
    "                m = (y2 - y1) / (x2 - x1)\n",
    "                table['cluster'] = table.apply(lambda row: 'left' if (row['predicted'] - y1) - m * (row['DMS_score'] - x1) > 0 else 'right', axis=1)\n",
    "                table.to_csv('D7PM05_CLYGR_Somermeyer_2022_linreg_clusters.csv', index=False)\n",
    "\n",
    "            if dataset == 'GFP_AEQVI_Sarkisyan_2016':\n",
    "                table = df[df['mutant'].isin(selected_mutations_2)][['mutant', 'DMS_score']]    \n",
    "                table['predicted'] = y_pred_2\n",
    "                x1, y1 = 5000, 10000\n",
    "                x2, y2 = 30000, 50000\n",
    "                m = (y2 - y1) / (x2 - x1)\n",
    "                table['cluster'] = table.apply(lambda row: 'left' if (row['predicted'] - y1) - m * (row['DMS_score'] - x1) > 0 else 'right', axis=1)\n",
    "                table.to_csv('GFP_AEQVI_Sarkisyan_2016_linreg_clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing spearman tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "selected_mutations = {}\n",
    "directory = 'data/ProteinGym_subs_apr_2024'\n",
    "\n",
    "for filename in os.listdir(directory): # iterate over datasets\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    dataset = filename.split('.')[0]\n",
    "    if os.path.isfile(file_path) and dataset in suitable_datasets:\n",
    "        df = pd.read_csv(file_path)\n",
    "        indices = {}\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 2: # find 2 mutations\n",
    "                indices[(mutations[0], mutations[1], ind)] = [-1, -1] # indices[mutation 1, mutation 2, index of the pair], and inside we store indices of individual mutations\n",
    "\n",
    "        for ind, row in df.iterrows():\n",
    "            mutations = row['mutant'].split(':')\n",
    "            if len(mutations) == 1: # match indices of the 2 mutations to a pair\n",
    "                for key, value in indices.items():\n",
    "                    if key[0] == mutations[0]:\n",
    "                        indices[key][0] = ind\n",
    "                    if key[1] == mutations[0]:\n",
    "                        indices[key][1] = ind\n",
    "\n",
    "        dic_final = {}\n",
    "        for key, value in indices.items():\n",
    "            if value[0] != -1 and value[1] != -1:\n",
    "                dic_final[key] = value\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        df['DMS_score_scaled'] = scaler.fit_transform(df['DMS_score'].values.reshape(-1, 1)) # minmax scale values\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        selected = []\n",
    "        for key, value in dic_final.items():\n",
    "            ind = key[2]\n",
    "            x.append(df.loc[ind, 'DMS_score_scaled']) # score for a pair\n",
    "            selected.append(key[0] + ':' + key[1])\n",
    "            ind_first = value[0]\n",
    "            ind_second = value[1]\n",
    "            y.append(df.loc[ind_first, 'DMS_score_scaled'] * df.loc[ind_second, 'DMS_score_scaled']) # multiplied individuals\n",
    "\n",
    "        # Calculate distances from the line y = x\n",
    "        distances = np.abs(np.array(y) - np.array(x)) / np.sqrt(2)\n",
    "        # Calculate mean and standard deviation of the distances\n",
    "        mean_distance = np.mean(distances)\n",
    "        std_distance = np.std(distances)\n",
    "        # Define a threshold for \"distinct\" points (e.g., 2 standard deviations from the mean)\n",
    "        threshold = mean_distance + 1 * std_distance\n",
    "        # Identify points that are \"distinct\"\n",
    "        distinct_points = distances > threshold\n",
    "        selected_muts_1 = [element for element, mask in zip(selected, distinct_points.tolist()) if mask] # for 1 std\n",
    "\n",
    "        threshold = mean_distance + 2 * std_distance\n",
    "        distinct_points = distances > threshold\n",
    "        selected_muts_2 = [element for element, mask in zip(selected, distinct_points.tolist()) if mask] # for 2 std\n",
    "        \n",
    "        selected_mutations[dataset] = (selected_muts_1, selected_muts_2)\n",
    "        dfs[dataset] = df# Iterate over all model prediction folders in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spearman(result_all, entry_path, model):\n",
    "    score_columns = []\n",
    "    score_indices = {}\n",
    "    for filename in os.listdir(entry_path): # let's just open 1 file and check if there're several rows with predictions (different num of parameters)\n",
    "        file_path = os.path.join(entry_path, filename)\n",
    "        dataset = filename.split('.')[0]\n",
    "        if dataset in suitable_datasets: \n",
    "            df = dfs[dataset]\n",
    "            df_pred = pd.read_csv(file_path)\n",
    "            for col in df_pred.columns:\n",
    "                if ('mut' not in col) and ('seq' not in col) and ('DMS_score' not in col):\n",
    "                    score_columns.append(col)\n",
    "            break\n",
    "    for score_column in score_columns:\n",
    "        new_row = pd.DataFrame(dict(zip(list(result_all.columns), [model + '_' + score_column] + [None]*(result_all.shape[1] - 1))), index=[0])\n",
    "        result_all = pd.concat([result_all, new_row], ignore_index=True) # SAVE INDICES + SCORE NAMES IN A DICT TO APPEND AFTERWARDS\n",
    "        score_indices[score_column] = result_all.index[-1]\n",
    "    for filename in os.listdir(entry_path): # iterate over datasets\n",
    "        file_path = os.path.join(entry_path, filename)\n",
    "        dataset = filename.split('.')[0]\n",
    "        if dataset in suitable_datasets: \n",
    "            df = dfs[dataset]\n",
    "            df_pred = pd.read_csv(file_path)\n",
    "            if 'mutant' in df_pred.columns:\n",
    "                if 'DMS_score' in df_pred.columns:\n",
    "                    merged_df = df.merge(df_pred, left_on=['mutant', 'DMS_score'], right_on=['mutant', 'DMS_score'])\n",
    "                else:\n",
    "                    merged_df = df.merge(df_pred, left_on='mutant', right_on='mutant')\n",
    "            else:\n",
    "                if 'DMS_score' in df_pred.columns:\n",
    "                    merged_df = df.merge(df_pred, left_on=['mutated_sequence', 'DMS_score'], right_on=['mutated_sequence', 'DMS_score'])\n",
    "                else:\n",
    "                    merged_df = df.merge(df_pred, left_on='mutated_sequence', right_on='mutated_sequence')\n",
    "\n",
    "            for score_column in score_columns: # calculate for all predicted scores\n",
    "                spearman_all = spearmanr(merged_df['DMS_score'], merged_df[score_column])[0]\n",
    "\n",
    "                merged_df['num_mutations'] = merged_df['mutant'].str.split(':').apply(len)\n",
    "                \n",
    "                selected_mutations_1, selected_mutations_2 = selected_mutations[dataset]\n",
    "                merged_df_selected_1 = merged_df[merged_df['mutant'].isin(selected_mutations_1)]\n",
    "                spearman_distinct_1 = spearmanr(merged_df_selected_1['DMS_score'], merged_df_selected_1[score_column])[0]\n",
    "                merged_df_selected_2 = merged_df[merged_df['mutant'].isin(selected_mutations_2)]\n",
    "                spearman_distinct_2 = spearmanr(merged_df_selected_2['DMS_score'], merged_df_selected_2[score_column])[0]\n",
    "\n",
    "                result_all.loc[score_indices[score_column], dataset + '_all'] = f\"{spearman_all:.2f}\"\n",
    "                result_all.loc[score_indices[score_column], dataset + '_1std'] = f\"{spearman_distinct_1:.2f}\"\n",
    "                result_all.loc[score_indices[score_column], dataset + '_2std'] = f\"{spearman_distinct_2:.2f}\"\n",
    "    return result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/zero_shot_substitutions_scores'\n",
    "for model in os.listdir(directory): # iterate over models\n",
    "    entry_path = os.path.join(directory, model)\n",
    "    if any(os.path.isdir(os.path.join(entry_path, entry)) for entry in os.listdir(entry_path)): # case when there are subfolders inside a model (different parameter number)\n",
    "        for folder_name in os.listdir(entry_path): # iterate over submodels\n",
    "            folder_path = os.path.join(entry_path, folder_name)\n",
    "            result_all = calculate_spearman(result_all, folder_path, model + '_' + folder_name)\n",
    "    else: # standart case\n",
    "        result_all = calculate_spearman(result_all, entry_path, model)\n",
    "result_all.to_csv('all_models.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add linreg baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all = pd.read_csv('all_models.csv', dtype=str)\n",
    "result_all.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(zip(['LinearRegression'], [LinearRegression]))\n",
    "indices = dict(zip(['LinearRegression'], [len(result_all)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in suitable_datasets:\n",
    "    df = dfs[dataset]\n",
    "    df['num_mutations'] = df['mutant'].str.split(':').apply(len)\n",
    "    enc = preprocessing.OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    max_len = max(len(seq) for seq in df.mutated_sequence)\n",
    "\n",
    "    sequences = list(df[df['mutant'].apply(lambda x: len(x.split(':')) == 1)].mutated_sequence)\n",
    "    \n",
    "    sequences = [list(seq) for seq in sequences]\n",
    "    padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "    padded_array = np.array(padded_sequences)\n",
    "    enc.fit(padded_array)\n",
    "    x_train = enc.transform(padded_array).toarray()\n",
    "    y_train = df[df['mutant'].apply(lambda x: len(x.split(':')) == 1)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    selected_mutations_1, selected_mutations_2 = selected_mutations[dataset]\n",
    "\n",
    "    x_test_1 = y_test_1 = x_test_2 = y_test_2 = None\n",
    "\n",
    "    sequences = df[df['mutant'].isin(selected_mutations_1)].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test_1 = enc.transform(padded_array).toarray()\n",
    "        y_test_1 = df[df['mutant'].isin(selected_mutations_1)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    sequences = df[df['mutant'].isin(selected_mutations_2)].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test_2 = enc.transform(padded_array).toarray()\n",
    "        y_test_2 = df[df['mutant'].isin(selected_mutations_2)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    for model in models:\n",
    "        result_all.loc[indices[model], 'model'] = model\n",
    "\n",
    "        model_dataset = models[model]()\n",
    "        model_dataset.fit(x_train, y_train)\n",
    "\n",
    "        sequences = list(df.mutated_sequence)\n",
    "        sequences = [list(seq) for seq in sequences]\n",
    "        padded_sequences = [seq + [''] * (max_len - len(seq)) for seq in sequences]\n",
    "        padded_array = np.array(padded_sequences)\n",
    "        x_test = enc.transform(padded_array).toarray()\n",
    "        y_test = df.DMS_score.values.reshape(-1,1)\n",
    "        y_pred = model_dataset.predict(x_test)\n",
    "        spearman = spearmanr(y_test, y_pred)[0]\n",
    "        result_all.loc[indices[model], dataset + '_all'] = spearman\n",
    "\n",
    "        if x_test_1 is not None:\n",
    "            y_pred_1 = model_dataset.predict(x_test_1)\n",
    "            spearman_distinct_1 = spearmanr(y_test_1, y_pred_1)[0]\n",
    "            result_all.loc[indices[model], dataset + '_1std'] = f\"{spearman_distinct_1:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_1std'] = 0\n",
    "\n",
    "        if x_test_2 is not None:\n",
    "            y_pred_2 = model_dataset.predict(x_test_2)\n",
    "            spearman_distinct_2 = spearmanr(y_test_2, y_pred_2)[0]\n",
    "            result_all.loc[indices[model], dataset + '_2std'] = f\"{spearman_distinct_2:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_2std'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all.to_csv('all_models.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'all_models.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "columns_to_consider = [col for col in data.columns if col.endswith('_all')]\n",
    "# Add a new column to identify categories (prefixes before '_')\n",
    "data['category'] = data['model'].str.split('_').str[0]\n",
    "# Group by category and find the best model in each group based on the highest mean(abs(row)) for '_all' columns\n",
    "results = data.groupby('category').apply(\n",
    "    lambda group: group.loc[group[columns_to_consider].abs().mean(axis=1).idxmax()]\n",
    ")\n",
    "\n",
    "results.to_csv('best_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of Spearman values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('/wibicomfs/STBS/anastasia/epistasis_prediction_review/best_models.csv', index_col=0)\n",
    "df.index = df.index.to_series().apply(lambda x: x.split('_')[0])\n",
    "df = df.loc[[i for i in df.index if i != 'LinearRegression'] + ['LinearRegression']]\n",
    "\n",
    "# Mapping dataset names for titles\n",
    "dick = {\n",
    "    'D7PM05_CLYGR_Somermeyer_2022': 'GFP from C. gregaria',\n",
    "    'F7YBW8_MESOW_Aakre_2015': 'Addition module antidote protein',\n",
    "    'GFP_AEQVI_Sarkisyan_2016': 'GFP from A. victoria'\n",
    "}\n",
    "\n",
    "# Loop through datasets and plot\n",
    "for dataset in ['D7PM05_CLYGR_Somermeyer_2022',\n",
    "                'F7YBW8_MESOW_Aakre_2015',\n",
    "                'GFP_AEQVI_Sarkisyan_2016']:\n",
    "    all = np.abs(df[dataset + '_all'])\n",
    "    std1 = np.abs(df[dataset + '_1std'])\n",
    "    std2 = np.abs(df[dataset + '_2std'])\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    categories = df.index  # Coordinates on the x-axis\n",
    "    x = np.arange(len(categories))  # Positions for the groups\n",
    "    width = 0.2  # Width of the bars\n",
    "\n",
    "    # Adjusted position of the dotted vertical line (to separate Linear Regression)\n",
    "    linear_reg_index = len(categories) - 1  # Index of Linear Regression\n",
    "    linear_reg_xpos = x[linear_reg_index] - 2.5 * width  # Adjusted to slightly left\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(18, 8))\n",
    "    ax.bar(x - width, all, width, color='midnightblue', label='All points')\n",
    "    ax.bar(x, std1, width, color='#fc5a03', label='Distant points (1 std)')\n",
    "    ax.bar(x + width, std2, width, color='#38a112', label='Distant points (2 std)')\n",
    "\n",
    "    # Add vertical line to separate Linear Regression\n",
    "    ax.axvline(linear_reg_xpos, color='red', linestyle='dotted', linewidth=1.5)\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xlabel('Model', fontsize=14)\n",
    "    ax.set_ylabel('Spearman correlation', fontsize=14)\n",
    "    ax.set_title(f'Spearman correlations for {dick[dataset]}', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.grid(True, axis='y')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.savefig(f'/wibicomfs/STBS/anastasia/epistasis_prediction_review/figures/paper/{dataset}.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/wibicomfs/STBS/anastasia/epistasis_prediction_review/all_models.csv', index_col=0)\n",
    "df = df.loc[[i for i in df.index if i != 'LinearRegression'] + ['LinearRegression']]\n",
    "dick = {'D7PM05_CLYGR_Somermeyer_2022': 'GFP from C. gregaria',\n",
    "                'F7YBW8_MESOW_Aakre_2015': 'Addition module antidote protein',\n",
    "                'GFP_AEQVI_Sarkisyan_2016': 'GFP from A. victoria'}\n",
    "for dataset in ['D7PM05_CLYGR_Somermeyer_2022',\n",
    "                'F7YBW8_MESOW_Aakre_2015',\n",
    "                'GFP_AEQVI_Sarkisyan_2016'] :\n",
    "    all = np.abs(df[dataset + '_all'])\n",
    "    std1 = np.abs(df[dataset + '_1std'])\n",
    "    std2 = np.abs(df[dataset + '_2std'])\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    #plt.figure(figsize=[34,38])\n",
    "    categories = df.index  # Coordinates on the x-axis\n",
    "    x = np.arange(len(categories))  # Positions for the groups\n",
    "    width = 0.2  # Width of the bars\n",
    "\n",
    "    # Adjusted position of the dotted vertical line (to separate Linear Regression)\n",
    "    linear_reg_index = len(categories) - 1  # Index of Linear Regression\n",
    "    linear_reg_xpos = x[linear_reg_index] - 2.5 * width  # Adjusted to slightly left\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(28, 8))\n",
    "    # Plot each set of bars with a specific x offset\n",
    "    ax.bar(x - width, all, width, color='midnightblue', label='All points')\n",
    "    ax.bar(x, std1, width, color='#fc5a03', label='Distant points (1 std)')\n",
    "    ax.bar(x + width, std2, width, color='#38a112', label='Distant points (2 std)')\n",
    "\n",
    "    # Add vertical line to separate Linear Regression\n",
    "    ax.axvline(linear_reg_xpos, color='red', linestyle='dotted', linewidth=1.5)\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xlabel('Model', fontsize=14)\n",
    "    ax.set_ylabel('Spearman correlation', fontsize=14)\n",
    "    ax.set_title(f'Spearman correlations for {dick[dataset]}', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.grid(True, axis='y')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.savefig(f'/wibicomfs/STBS/anastasia/epistasis_prediction_review/figures/paper/{dataset}_supp.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitable_datasets = []\n",
    "with open('../selected_datasets.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        dataset = line.strip()\n",
    "        suitable_datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../all_Spearman_values.csv', index_col=1)\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "for dataset in suitable_datasets:\n",
    "    all = np.abs(df[dataset + '_Spearman_all'])\n",
    "    std1 = np.abs(df[dataset + '_Spearman_distinct_1std'])\n",
    "    std2 = np.abs(df[dataset + '_Spearman_distinct_2std'])\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    #plt.figure(figsize=[34,38])\n",
    "    categories = df.index  # Coordinates on the x-axis\n",
    "    x = np.arange(len(categories))  # Positions for the groups\n",
    "    width = 0.2  # Width of the bars\n",
    "    fig, ax = plt.subplots(figsize=(28, 8))\n",
    "    # Plot each set of bars with a specific x offset\n",
    "    ax.bar(x - width, all, width, color='midnightblue', label='All points')\n",
    "    ax.bar(x, std1, width, color=cmap(1), label='Distant points (1 std)')\n",
    "    ax.bar(x + width, std2, width, color=cmap(0), label='Distant points (2 std)')\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xlabel('Model', fontsize=14)\n",
    "    ax.set_ylabel('Spearman correlation', fontsize=14)\n",
    "    ax.set_title(f'Spearman correlations for {dataset}', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.grid(True, axis='y')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.savefig(f'../figures/plots_models/{dataset}.svg', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double/multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../all_Spearman_values.csv', index_col=1)\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "for dataset in suitable_datasets:\n",
    "    doubles = np.abs(df[dataset + '_Spearman_doubles'])\n",
    "    multi = np.abs(df[dataset + '_Spearman_multi'])\n",
    "    std1 = np.abs(df[dataset + '_Spearman_distinct_1std'])\n",
    "    std2 = np.abs(df[dataset + '_Spearman_distinct_2std'])\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    #plt.figure(figsize=[34,38])\n",
    "    categories = df.index  # Coordinates on the x-axis\n",
    "    x = np.arange(len(categories))  # Positions for the groups\n",
    "    width = 0.2  # Width of the bars\n",
    "    fig, ax = plt.subplots(figsize=(28, 8))\n",
    "    # Plot each set of bars with a specific x offset\n",
    "    ax.bar(x - 1.5*width, doubles, width, color=cmap(6), label='Double mutations')\n",
    "    ax.bar(x - width/2, multi, width, color=cmap(7), label='Multi (2+) mutations')\n",
    "    ax.bar(x + width/2, std1, width, color=cmap(1), label='Distant points (1 std)')\n",
    "    ax.bar(x + 1.5*width, std2, width, color=cmap(0), label='Distant points (2 std)')\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xlabel('Model', fontsize=14)\n",
    "    ax.set_ylabel('Spearman correlation', fontsize=14)\n",
    "    ax.set_title(f'Spearman correlations for {dataset}', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.grid(True, axis='y')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.savefig(f'../figures/plots_models/{dataset}_multi.svg', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def rename_columns(col, num):\n",
    "    parts = col.split('_')  # Split by '_'\n",
    "    return '_'.join(parts[:len(parts) - num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = ['_Spearman_all', '_Spearman_doubles', '_Spearman_multi', '_Spearman_distinct_1std', '_Spearman_distinct_2std']\n",
    "cnt = 0\n",
    "for plot in plots:\n",
    "    df_slice = np.abs(df.filter(like=plot))\n",
    "    if cnt < 3:\n",
    "        df_slice.columns = [rename_columns(col, 2) for col in df_slice.columns]\n",
    "    else:\n",
    "        df_slice.columns = [rename_columns(col, 3) for col in df_slice.columns]\n",
    "    cnt += 1\n",
    "    df_slice.fillna(0, inplace=True)\n",
    "    plt.figure(figsize=[28,8])\n",
    "    sns.violinplot(df_slice)\n",
    "    plt.xlabel('Datasets', fontsize=14)\n",
    "    plt.ylabel('Spearman correlation', fontsize=14)\n",
    "    plt.title(f'Spearman correlation of all methods ({plot.split('_')[-1]} points)', fontsize=16)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.savefig(f'../figures/violin_plots/{plot[1:]}.svg', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('best_models.csv')\n",
    "\n",
    "# List of selected columns (datasets) to include in the plot\n",
    "selected_columns = [\n",
    "    \"D7PM05_CLYGR_Somermeyer_2022_all\", \"D7PM05_CLYGR_Somermeyer_2022_1std\", \"D7PM05_CLYGR_Somermeyer_2022_2std\",\n",
    "    \"F7YBW8_MESOW_Aakre_2015_all\", \"F7YBW8_MESOW_Aakre_2015_1std\", \"F7YBW8_MESOW_Aakre_2015_2std\",\n",
    "    \"GFP_AEQVI_Sarkisyan_2016_all\", \"GFP_AEQVI_Sarkisyan_2016_1std\", \"GFP_AEQVI_Sarkisyan_2016_2std\"\n",
    "]\n",
    "\n",
    "# Add the 'model' column to the selected columns for context\n",
    "columns_to_plot = [\"model\"] + selected_columns\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_data = data[columns_to_plot]\n",
    "# Take the absolute value of all numerical columns\n",
    "filtered_data[selected_columns] = filtered_data[selected_columns].abs()\n",
    "# Remove rows which have 'LinearRegression' in the 'model' column\n",
    "filtered_data = filtered_data[~filtered_data['model'].str.contains('LinearRegression')]\n",
    "# Melt the filtered DataFrame into long format for plotting\n",
    "df_melted = filtered_data.melt(id_vars=[\"model\"], var_name=\"Dataset\", value_name=\"Spearman correlation\")\n",
    "df_melted.to_csv('tabel.csv')\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define a custom color palette\n",
    "palette = [\n",
    "    \"#ff7051\", \"#ff7051\", \"#ff7051\",  # Colors for D7PM05_CLYGR (orange shades)\n",
    "    \"#709ac6\", \"#709ac6\", \"#709ac6\",  # Colors for F7YBW8_MESOW (blue shades)\n",
    "    \"#7cc670\", \"#7cc670\", \"#7cc670\"   # Colors for GFP_AEQVI (green shades)\n",
    "]\n",
    "\n",
    "# Create the violin plot\n",
    "sns.violinplot(\n",
    "    data=df_melted,\n",
    "    x=\"Dataset\",\n",
    "    y=\"Spearman correlation\",\n",
    "    palette=palette,\n",
    "    scale=\"width\",\n",
    "    inner=\"box\"\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.ylabel(\"Spearman correlation\", fontsize=14)\n",
    "\n",
    "# Custom x-tick labels\n",
    "custom_labels = [\n",
    "    \"all\", \"weakly epistasis\", \"strongly epistasis\",\n",
    "    \"all\", \"weakly epistasis\", \"strongly epistasis\",\n",
    "    \"all\", \"weakly epistasis\", \"strongly epistasis\"\n",
    "]\n",
    "plt.xticks(ticks=range(len(custom_labels)), labels=custom_labels, rotation=45, fontsize=14, ha='right')\n",
    "\n",
    "# Remove x-axis label\n",
    "plt.xlabel(None)\n",
    "\n",
    "# Add a legend for the colors\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"#ff7051\", edgecolor='k', label=\"GFP from C. gregaria\"),\n",
    "    Patch(facecolor=\"#709ac6\", edgecolor='k', label=\"Addition module antidote protein\"),\n",
    "    Patch(facecolor=\"#7cc670\", edgecolor='k', label=\"GFP from A. victoria\")\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc=\"upper center\", fontsize=12, title_fontsize=14)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig('figures/paper/2.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('tabel.csv')  # Replace with your actual file name\n",
    "\n",
    "# Calculate summary statistics\n",
    "statistics_summary = data.groupby('Dataset')['Spearman correlation'].agg(\n",
    "    median='median',\n",
    "    min='min',\n",
    "    max='max',\n",
    "    mean='mean',\n",
    "    std='std'\n",
    ").reset_index()\n",
    "\n",
    "# Reorder the rows to match the order in the violin plot\n",
    "selected_columns_order = [\n",
    "    \"D7PM05_CLYGR_Somermeyer_2022_all\", \"D7PM05_CLYGR_Somermeyer_2022_1std\", \"D7PM05_CLYGR_Somermeyer_2022_2std\",\n",
    "    \"F7YBW8_MESOW_Aakre_2015_all\", \"F7YBW8_MESOW_Aakre_2015_1std\", \"F7YBW8_MESOW_Aakre_2015_2std\",\n",
    "    \"GFP_AEQVI_Sarkisyan_2016_all\", \"GFP_AEQVI_Sarkisyan_2016_1std\", \"GFP_AEQVI_Sarkisyan_2016_2std\"\n",
    "]\n",
    "\n",
    "# Reorder the DataFrame to match the selected_columns order\n",
    "statistics_summary = statistics_summary.set_index('Dataset')\n",
    "statistics_summary = statistics_summary.loc[selected_columns_order].reset_index()\n",
    "\n",
    "statistics_summary.to_csv('table1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('all_models.csv')\n",
    "\n",
    "# List of selected columns (datasets) to include in the plot\n",
    "selected_columns = [\n",
    "    \"D7PM05_CLYGR_Somermeyer_2022_all\", \"D7PM05_CLYGR_Somermeyer_2022_1std\", \"D7PM05_CLYGR_Somermeyer_2022_2std\",\n",
    "    \"F7YBW8_MESOW_Aakre_2015_all\", \"F7YBW8_MESOW_Aakre_2015_1std\", \"F7YBW8_MESOW_Aakre_2015_2std\",\n",
    "    \"GFP_AEQVI_Sarkisyan_2016_all\", \"GFP_AEQVI_Sarkisyan_2016_1std\", \"GFP_AEQVI_Sarkisyan_2016_2std\"\n",
    "]\n",
    "\n",
    "# Add the 'model' column to the selected columns for context\n",
    "columns_to_plot = [\"model\"] + selected_columns\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_data = data[columns_to_plot]\n",
    "# Take the absolute value of all numerical columns\n",
    "filtered_data[selected_columns] = filtered_data[selected_columns].abs()\n",
    "# Remove rows which have 'LinearRegression' in the 'model' column\n",
    "filtered_data = filtered_data[~filtered_data['model'].str.contains('LinearRegression')]\n",
    "# Melt the filtered DataFrame into long format for plotting\n",
    "df_melted = filtered_data.melt(id_vars=[\"model\"], var_name=\"Dataset\", value_name=\"Spearman correlation\")\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define a custom color palette\n",
    "palette = [\n",
    "    \"#ff7051\", \"#ff7051\", \"#ff7051\",  # Colors for D7PM05_CLYGR (orange shades)\n",
    "    \"#709ac6\", \"#709ac6\", \"#709ac6\",  # Colors for F7YBW8_MESOW (blue shades)\n",
    "    \"#7cc670\", \"#7cc670\", \"#7cc670\"   # Colors for GFP_AEQVI (green shades)\n",
    "]\n",
    "\n",
    "# Create the violin plot\n",
    "sns.violinplot(\n",
    "    data=df_melted,\n",
    "    x=\"Dataset\",\n",
    "    y=\"Spearman correlation\",\n",
    "    palette=palette,\n",
    "    scale=\"width\",\n",
    "    inner=\"box\"\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.ylabel(\"Spearman correlation\", fontsize=14)\n",
    "\n",
    "# Custom x-tick labels\n",
    "custom_labels = [\n",
    "    \"all\", \"weakly epistasis\", \"strongly epistasis\",\n",
    "    \"all\", \"weakly epistasis\", \"strongly epistasis\",\n",
    "    \"all\", \"weakly epistasis\", \"strongly epistasis\"\n",
    "]\n",
    "plt.xticks(ticks=range(len(custom_labels)), labels=custom_labels, rotation=45, fontsize=14, ha='right')\n",
    "\n",
    "# Remove x-axis label\n",
    "plt.xlabel(None)\n",
    "\n",
    "# Add a legend for the colors\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"#ff7051\", edgecolor='k', label=\"GFP from C. gregaria\"),\n",
    "    Patch(facecolor=\"#709ac6\", edgecolor='k', label=\"Addition module antidote protein\"),\n",
    "    Patch(facecolor=\"#7cc670\", edgecolor='k', label=\"GFP from A. victoria\")\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc=\"upper center\", fontsize=12, title_fontsize=14)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig('figures/paper/supp3.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Almost) constant linreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding: seq[i] = 1 if there's a mutation on pos i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitable_datasets = []\n",
    "cols = ['model']\n",
    "with open('/home/ank24/epistasis_prediction_review/selected_datasets.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        dataset = line.strip()\n",
    "        suitable_datasets.append(dataset)\n",
    "        cols.append(dataset + '_Spearman_all')\n",
    "        cols.append(dataset + '_Spearman_doubles')\n",
    "        cols.append(dataset + '_Spearman_multi')\n",
    "        cols.append(dataset + '_Spearman_distinct_1std')\n",
    "        cols.append(dataset + '_Spearman_distinct_2std')\n",
    "result_all = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(zip(['LinearRegression', 'Ridge'], [LinearRegression, Ridge]))\n",
    "indices = dict(zip(['LinearRegression', 'Ridge'], [0, 1]))\n",
    "\n",
    "for dataset in suitable_datasets:\n",
    "    df = dfs[dataset]\n",
    "    df['mutations'] = df['mutant'].str.split(':')\n",
    "    x_train = []\n",
    "    maxlen = 0\n",
    "    for seq in df[\"mutated_sequence\"]:\n",
    "        if len(seq) > maxlen:\n",
    "            maxlen = len(seq)\n",
    "    for index, row in df[df['mutant'].apply(lambda x: len(x.split(':')) == 1)].iterrows(): # only single mutations\n",
    "        base = [0]*max_len\n",
    "        for pos in row['mutations']:\n",
    "            base[int(pos[1:len(pos)-1]) - 1] = 1\n",
    "        x_train.append(base)\n",
    "\n",
    "    y_train = df[df['mutant'].apply(lambda x: len(x.split(':')) == 1)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    selected_mutations_1, selected_mutations_2 = selected_mutations[dataset]\n",
    "\n",
    "    x_test_doubles = y_test_doubles = x_test_multi = y_test_multi = x_test_1 = y_test_1 = x_test_2 = y_test_2 = None\n",
    "\n",
    "    sequences = df[df['num_mutations'] == 2].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        x_test_doubles = []\n",
    "        for index, row in df[df['num_mutations'] == 2].iterrows():\n",
    "            base = [0]*max_len\n",
    "            for pos in row['mutations']:\n",
    "                base[int(pos[1:len(pos)-1]) - 1] = 1\n",
    "            x_test_doubles.append(base)\n",
    "        y_test_doubles = df[df['num_mutations'] == 2].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    sequences = df[df['num_mutations'] >= 2].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        x_test_multi = []\n",
    "        for index, row in df[df['num_mutations'] >= 2].iterrows():\n",
    "            base = [0]*max_len\n",
    "            for pos in row['mutations']:\n",
    "                base[int(pos[1:len(pos)-1]) - 1] = 1\n",
    "            x_test_multi.append(base)\n",
    "        y_test_multi = df[df['num_mutations'] >= 2].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    sequences = df[df['mutant'].isin(selected_mutations_1)].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        x_test_1 = []\n",
    "        for index, row in df[df['mutant'].isin(selected_mutations_1)].iterrows():\n",
    "            base = [0]*max_len\n",
    "            for pos in row['mutations']:\n",
    "                base[int(pos[1:len(pos)-1]) - 1] = 1\n",
    "            x_test_1.append(base)\n",
    "        y_test_1 = df[df['mutant'].isin(selected_mutations_1)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    sequences = df[df['mutant'].isin(selected_mutations_2)].mutated_sequence\n",
    "    if len(sequences) != 0:\n",
    "        x_test_2 = []\n",
    "        for index, row in df[df['mutant'].isin(selected_mutations_2)].iterrows():\n",
    "            base = [0]*max_len\n",
    "            for pos in row['mutations']:\n",
    "                base[int(pos[1:len(pos)-1]) - 1] = 1\n",
    "            x_test_2.append(base)\n",
    "        y_test_2 = df[df['mutant'].isin(selected_mutations_2)].DMS_score.values.reshape(-1,1)\n",
    "\n",
    "    for model in models:\n",
    "        result_all.loc[indices[model], 'model'] = model\n",
    "\n",
    "        model_dataset = models[model]()\n",
    "        model_dataset.fit(x_train, y_train)\n",
    "\n",
    "        x_test = []\n",
    "        for index, row in df.iterrows():\n",
    "            base = [0]*max_len\n",
    "            for pos in row['mutations']:\n",
    "                base[int(pos[1:len(pos)-1]) - 1] = 1\n",
    "            x_test.append(base)\n",
    "\n",
    "        y_test = df.DMS_score.values.reshape(-1,1)\n",
    "        y_pred = model_dataset.predict(x_test)\n",
    "        spearman = spearmanr(y_test, y_pred)[0]\n",
    "        result_all.loc[indices[model], dataset + '_Spearman_all'] = spearman\n",
    "\n",
    "        if x_test_doubles is not None:\n",
    "            y_pred_doubles = model_dataset.predict(x_test_doubles)\n",
    "            spearman_doubles = spearmanr(y_test_doubles, y_pred_doubles)[0]\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_doubles'] = f\"{spearman_doubles:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_doubles'] = 0\n",
    "\n",
    "        if x_test_multi is not None:\n",
    "            y_pred = model_dataset.predict(x_test_multi)\n",
    "            spearman = spearmanr(y_test_multi, y_pred)[0]\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_multi'] = f\"{spearman:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_multi'] = 0\n",
    "\n",
    "        if x_test_1 is not None:\n",
    "            y_pred_1 = model_dataset.predict(x_test_1)\n",
    "            spearman_distinct_1 = spearmanr(y_test_1, y_pred_1)[0]\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_distinct_1std'] = f\"{spearman_distinct_1:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_distinct_1std'] = 0\n",
    "\n",
    "        if x_test_2 is not None:\n",
    "            y_pred_2 = model_dataset.predict(x_test_2)\n",
    "            spearman_distinct_2 = spearmanr(y_test_2, y_pred_2)[0]\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_distinct_2std'] = f\"{spearman_distinct_2:.2f}\"\n",
    "        else:\n",
    "            result_all.loc[indices[model], dataset + '_Spearman_distinct_2std'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all.to_csv('../constant_linreg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../constant_linreg.csv', index_col=1)\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "for dataset in suitable_datasets:\n",
    "    all = np.abs(df[dataset + '_Spearman_all'])\n",
    "    doubles = np.abs(df[dataset + '_Spearman_doubles'])\n",
    "    multi = np.abs(df[dataset + '_Spearman_multi'])\n",
    "    std1 = np.abs(df[dataset + '_Spearman_distinct_1std'])\n",
    "    std2 = np.abs(df[dataset + '_Spearman_distinct_2std'])\n",
    "    cmap = plt.get_cmap('Paired')\n",
    "    #plt.figure(figsize=[34,38])\n",
    "    categories = df.index  # Coordinates on the x-axis\n",
    "    x = np.arange(len(categories))  # Positions for the groups\n",
    "    width = 0.1  # Width of the bars\n",
    "    fig, ax = plt.subplots(figsize=(18, 8))\n",
    "    # Plot each set of bars with a specific x offset\n",
    "    ax.bar(x - 2*width, all, width, color=cmap(4), label='All points')\n",
    "    ax.bar(x - width, doubles, width, color=cmap(6), label='Double mutations')\n",
    "    ax.bar(x, multi, width, color=cmap(7), label='Multi (2+) mutations')\n",
    "    ax.bar(x + width, std1, width, color=cmap(1), label='Distant points (1 std)')\n",
    "    ax.bar(x + 2*width, std2, width, color=cmap(0), label='Distant points (2 std)')\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_xlabel('Model', fontsize=14)\n",
    "    ax.set_ylabel('Spearman correlation', fontsize=14)\n",
    "    ax.set_title(f'Spearman correlations for {dataset}', fontsize=16)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.grid(True, axis='y')\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.savefig(f'../figures/plots_linreg/{dataset}.svg', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[\"D7PM05_CLYGR_Somermeyer_2022\"]\n",
    "df['mutations'] = df['mutant'].str.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['mutant'].apply(lambda x: len(x.split(':')) == 2)]['DMS_score_scaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[9,6])\n",
    "plt.hist(df[df['mutant'].apply(lambda x: len(x.split(':')) == 4)]['DMS_score_scaled'], bins=100, color='green')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Scaled fluorescence value\")\n",
    "plt.ylabel(\"Number of sequences\")\n",
    "plt.title(\"GFP Clytia 4 mutations\")\n",
    "plt.savefig(f'../figures/GFP_Sommermeyer_4.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
